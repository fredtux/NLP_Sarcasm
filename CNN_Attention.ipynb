{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-03T06:57:14.440942Z","iopub.status.busy":"2024-04-03T06:57:14.440510Z","iopub.status.idle":"2024-04-03T06:57:18.878277Z","shell.execute_reply":"2024-04-03T06:57:18.877285Z","shell.execute_reply.started":"2024-04-03T06:57:14.440906Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","# import tensorflow as tf\n","\n","# Use torch gpu\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# device = torch.device(\"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T06:57:18.880223Z","iopub.status.busy":"2024-04-03T06:57:18.879826Z","iopub.status.idle":"2024-04-03T06:57:25.365614Z","shell.execute_reply":"2024-04-03T06:57:25.364560Z","shell.execute_reply.started":"2024-04-03T06:57:18.880196Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/2847206600.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  train_data['class'] = train_data['class'].replace(True, 1).replace(False, 0)\n"]}],"source":["# Get data\n","train_data = pd.read_csv('/kaggle/input/nitro2024/train.csv')\n","test_data = pd.read_csv('/kaggle/input/nitro2024/test.csv')\n","\n","train_data['class'] = train_data['class'].replace(True, 1).replace(False, 0)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T06:57:25.366989Z","iopub.status.busy":"2024-04-03T06:57:25.366693Z","iopub.status.idle":"2024-04-03T06:57:27.694163Z","shell.execute_reply":"2024-04-03T06:57:27.693168Z","shell.execute_reply.started":"2024-04-03T06:57:25.366965Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModel\n","from torch import nn\n","from torch.optim import Adam\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T06:57:27.697461Z","iopub.status.busy":"2024-04-03T06:57:27.696590Z","iopub.status.idle":"2024-04-03T06:58:07.085658Z","shell.execute_reply":"2024-04-03T06:58:07.084906Z","shell.execute_reply.started":"2024-04-03T06:57:27.697427Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9a1d97cd0d34c088332de9917f38bf5","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/456 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10a357be631542e98308812e576dc5e7","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/397k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b70dc2ce09e41e88738fa2131c7e1ae","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.19M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e552bc4784b4ad09375323ca0bd597c","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0194e111404a440e85490089335c3101","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4b5f2f66f9b4785a984bf936a13a8f4","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"Alegzandra/romanian_bert-finetuned-on-REDv2-romanian\")\n","model = AutoModel.from_pretrained(\"Alegzandra/romanian_bert-finetuned-on-REDv2-romanian\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T06:58:07.088061Z","iopub.status.busy":"2024-04-03T06:58:07.086953Z","iopub.status.idle":"2024-04-03T06:58:08.787669Z","shell.execute_reply":"2024-04-03T06:58:08.786860Z","shell.execute_reply.started":"2024-04-03T06:58:07.088026Z"},"trusted":true},"outputs":[],"source":["new_train_data = []\n","for i in range(len(train_data)):\n","    new_train_data.append((str(train_data['title'][i]) + \" \" + str(train_data[\"content\"][i])).replace(\"\\n\", \" \"))\n","# for i in range(10):\n","#     print(new_train_data[i], end=\"\\n\\n\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T06:58:08.789508Z","iopub.status.busy":"2024-04-03T06:58:08.789066Z","iopub.status.idle":"2024-04-03T06:58:08.815548Z","shell.execute_reply":"2024-04-03T06:58:08.814576Z","shell.execute_reply.started":"2024-04-03T06:58:08.789474Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","config = {\n","    \"max_sen_len\": 512,\n","    'n_gram': 1,\n","    \"batch_size\": 4\n","}\n","\n","class CNN(nn.Module):\n","    def __init__(self, alegzandra_finetuned_bert):\n","        super(CNN, self).__init__()\n","        self.alegzandra_finetuned_bert = alegzandra_finetuned_bert\n","        # 2 CNN layers and 1 linear layer for binary classification\n","        self.linear = nn.Linear(768, 2)\n","        self.cnn1 = nn.Conv1d(768, 256, 2)\n","        self.cnn2 = nn.Conv1d(256, 768, 2)\n","        self.relu = nn.ReLU()\n","        self.maxpool = nn.AdaptiveMaxPool1d(1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.phrase_attention = Phrase_attention()\n","        self.self_attention = Self_Attention()\n","        \n","    def forward(self, p_input_ids, p_attention_mask):\n","        with torch.no_grad():\n","            x = self.alegzandra_finetuned_bert(input_ids=p_input_ids, attention_mask=p_attention_mask).last_hidden_state\n","\n","        # x = x.unsqueeze(1)\n","        x = x.permute(0, 2, 1)\n","        # x = x.transpose(2, 1)\n","        \n","        # x = x.permute(1,0,2,3)\n","        \n","        # print(x.shape)\n","        \n","        # x is input [16, 512, 768] make it [768, 16, 512]\n","        # x = x.permute(2, 0, 1)\n","        \n","        # print('------')\n","#         print('Starting CNN')\n","        x = self.cnn1(x)\n","        # print(x.shape)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        # print(x.shape)\n","        # print('=============')\n","        # print(x.shape)\n","        \n","        x = self.cnn2(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        \n","        x = self.maxpool(x).squeeze(2)\n","\n","        # print(x.shape)\n","        # print('------')\n","        \n","        # x = x.transpose(0, 2)  \n","        s_a = []\n","        for i in range(len(x)):\n","            # print(i)\n","            text = x[i].unsqueeze(0).unsqueeze(0).permute(1, 2, 0)\n","            # print(text.shape)\n","            p_a = self.phrase_attention(text)\n","            # print('++++++++++')\n","            # print(p_a.shape)\n","            # print(text.shape)\n","            # print(p_a.unsqueeze(2).shape)\n","            \n","            s_a.append(self.self_attention(p_a * text).unsqueeze(2))\n","        \n","        # List of tensors to tensor\n","        s_a = torch.cat(s_a, dim=2).permute(2,0,1,3).to(device)\n","        # print(s_a.shape)\n","        \n","        x = self.maxpool(x)\n","        x = self.linear(s_a)\n","        # Exclude dimension 2\n","        x = x.view(x.size(0), -1)\n","        \n","        \n","        # print(x.shape)\n","        # x = x.squeeze(0)\n","        # x = x.transpose(0, 1)\n","        return x \n","    \n","class Phrase_attention(nn.Module):\n","    def __init__(self):\n","        super(Phrase_attention, self).__init__()\n","        self.linear = nn.Linear(1, 768)\n","        self.tanh = nn.Tanh()\n","        self.u_w = nn.Parameter(nn.init.xavier_uniform_(torch.FloatTensor(768, 1)))\n","\n","    def forward(self, embedding):\n","        # print(\"PA\")\n","        # print(embedding.shape)\n","        u_t = self.tanh(self.linear(embedding))\n","        # u_t = u_t.transpose(0, 1)\n","        \n","        a = torch.matmul(u_t, self.u_w)\n","        # print('++++++++++')\n","        \n","        # print(a.shape)\n","        a = a.squeeze(2)\n","        # print('++++++++++')\n","        \n","        \n","        a = F.log_softmax(a, dim=1)\n","        \n","        return a\n","\n","class Self_Attention(nn.Module):\n","    def __init__(self):\n","        super(Self_Attention, self).__init__()\n","        self.w1 = nn.Parameter(nn.init.xavier_uniform_(torch.FloatTensor(768, 1)))\n","        \n","        self.w2 = nn.Parameter(nn.init.xavier_uniform_(torch.FloatTensor(768, 1)))\n","        \n","        self.b = nn.Parameter(torch.FloatTensor(torch.randn(1)))\n","\n","    def forward(self, embedding):\n","        f1 = torch.matmul(embedding, self.w1)\n","\n","        # print('////////////////////')\n","        # print(f1.shape)        \n","        f2 = torch.matmul(embedding, self.w2)\n","        # print(f2.shape)\n","        \n","        f1 = f1.repeat(1, 1, embedding.size(1))\n","        # print(f1.shape)\n","        \n","        f2 = f2.repeat(1, 1, embedding.size(1))\n","        # print(f2.shape)\n","        \n","\n","        f1 = f1\n","        S = f1 + f2 + self.b\n","        # S = S + self.b\n","        \n","        mask = torch.eye(768).type(torch.ByteTensor)\n","        # print('111')\n","        # print(S.shape)\n","        # print(S.shape)\n","        S = S.transpose(0,1)\n","        # print(embedding.shape)\n","        # print(S.shape)\n","        S = S.masked_fill(mask.bool().to(device), -float('inf'))\n","        # print('222')\n","        \n","        # print(S.shape)\n","        # print('333')\n","        max_row = F.max_pool1d(S, kernel_size=embedding.size(1), stride=1)\n","        # max_row.transpose(1, 2)\n","        # print(max_row.shape)\n","        a = F.softmax(max_row, dim=1).transpose(1, 2)\n","        # print(a.shape)\n","        embedding = embedding.squeeze(0)\n","        # print(embedding.shape)\n","        \n","        v_a = torch.matmul(a, embedding)\n","\n","        return v_a\n","        "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T06:58:08.817065Z","iopub.status.busy":"2024-04-03T06:58:08.816789Z","iopub.status.idle":"2024-04-03T10:41:15.630893Z","shell.execute_reply":"2024-04-03T10:41:15.629922Z","shell.execute_reply.started":"2024-04-03T06:58:08.817032Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","tensor(12.6981, device='cuda:0', grad_fn=<NllLossBackward0>)\n","1000\n","tensor(7.0765, device='cuda:0', grad_fn=<NllLossBackward0>)\n","2000\n","tensor(6.9895, device='cuda:0', grad_fn=<NllLossBackward0>)\n","3000\n","tensor(7.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n","4000\n","tensor(6.8280, device='cuda:0', grad_fn=<NllLossBackward0>)\n","5000\n","tensor(6.6553, device='cuda:0', grad_fn=<NllLossBackward0>)\n","6000\n","tensor(6.8117, device='cuda:0', grad_fn=<NllLossBackward0>)\n","7000\n","tensor(6.8547, device='cuda:0', grad_fn=<NllLossBackward0>)\n","8000\n","tensor(6.8030, device='cuda:0', grad_fn=<NllLossBackward0>)\n","9000\n","tensor(7.3061, device='cuda:0', grad_fn=<NllLossBackward0>)\n","10000\n","tensor(6.6736, device='cuda:0', grad_fn=<NllLossBackward0>)\n","11000\n","tensor(6.6845, device='cuda:0', grad_fn=<NllLossBackward0>)\n","12000\n","tensor(6.7641, device='cuda:0', grad_fn=<NllLossBackward0>)\n","13000\n","tensor(6.8447, device='cuda:0', grad_fn=<NllLossBackward0>)\n","14000\n","tensor(6.8983, device='cuda:0', grad_fn=<NllLossBackward0>)\n","15000\n","tensor(6.7707, device='cuda:0', grad_fn=<NllLossBackward0>)\n","16000\n","tensor(6.8863, device='cuda:0', grad_fn=<NllLossBackward0>)\n","17000\n","tensor(6.8821, device='cuda:0', grad_fn=<NllLossBackward0>)\n","18000\n","tensor(7.1824, device='cuda:0', grad_fn=<NllLossBackward0>)\n","19000\n","tensor(7.1231, device='cuda:0', grad_fn=<NllLossBackward0>)\n","20000\n","tensor(6.7927, device='cuda:0', grad_fn=<NllLossBackward0>)\n","21000\n","tensor(6.6443, device='cuda:0', grad_fn=<NllLossBackward0>)\n","22000\n","tensor(6.9583, device='cuda:0', grad_fn=<NllLossBackward0>)\n","23000\n","tensor(6.7463, device='cuda:0', grad_fn=<NllLossBackward0>)\n","24000\n","tensor(6.9231, device='cuda:0', grad_fn=<NllLossBackward0>)\n","25000\n","tensor(6.8447, device='cuda:0', grad_fn=<NllLossBackward0>)\n","26000\n","tensor(6.6438, device='cuda:0', grad_fn=<NllLossBackward0>)\n","27000\n","tensor(6.8249, device='cuda:0', grad_fn=<NllLossBackward0>)\n","28000\n","tensor(6.7348, device='cuda:0', grad_fn=<NllLossBackward0>)\n","29000\n","tensor(6.7024, device='cuda:0', grad_fn=<NllLossBackward0>)\n","30000\n","tensor(6.7324, device='cuda:0', grad_fn=<NllLossBackward0>)\n","31000\n","tensor(6.8218, device='cuda:0', grad_fn=<NllLossBackward0>)\n","32000\n","tensor(6.8148, device='cuda:0', grad_fn=<NllLossBackward0>)\n","33000\n","tensor(6.7441, device='cuda:0', grad_fn=<NllLossBackward0>)\n","34000\n","tensor(6.8091, device='cuda:0', grad_fn=<NllLossBackward0>)\n","35000\n","tensor(6.8007, device='cuda:0', grad_fn=<NllLossBackward0>)\n","36000\n","tensor(6.8891, device='cuda:0', grad_fn=<NllLossBackward0>)\n","37000\n","tensor(6.7176, device='cuda:0', grad_fn=<NllLossBackward0>)\n","38000\n","tensor(6.7224, device='cuda:0', grad_fn=<NllLossBackward0>)\n","39000\n","tensor(7.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n","40000\n","tensor(6.8498, device='cuda:0', grad_fn=<NllLossBackward0>)\n","41000\n","tensor(6.6441, device='cuda:0', grad_fn=<NllLossBackward0>)\n","42000\n","tensor(6.7979, device='cuda:0', grad_fn=<NllLossBackward0>)\n","43000\n","tensor(6.9577, device='cuda:0', grad_fn=<NllLossBackward0>)\n","44000\n","tensor(6.7122, device='cuda:0', grad_fn=<NllLossBackward0>)\n","45000\n","tensor(6.7673, device='cuda:0', grad_fn=<NllLossBackward0>)\n","46000\n","tensor(6.6671, device='cuda:0', grad_fn=<NllLossBackward0>)\n","47000\n","tensor(6.6438, device='cuda:0', grad_fn=<NllLossBackward0>)\n","48000\n","tensor(6.7014, device='cuda:0', grad_fn=<NllLossBackward0>)\n","49000\n","tensor(6.7694, device='cuda:0', grad_fn=<NllLossBackward0>)\n","50000\n","tensor(6.7103, device='cuda:0', grad_fn=<NllLossBackward0>)\n","51000\n","tensor(6.6974, device='cuda:0', grad_fn=<NllLossBackward0>)\n","52000\n","tensor(6.8316, device='cuda:0', grad_fn=<NllLossBackward0>)\n","53000\n","tensor(6.7591, device='cuda:0', grad_fn=<NllLossBackward0>)\n","54000\n","tensor(6.8105, device='cuda:0', grad_fn=<NllLossBackward0>)\n","55000\n","tensor(6.9751, device='cuda:0', grad_fn=<NllLossBackward0>)\n","56000\n","tensor(6.6452, device='cuda:0', grad_fn=<NllLossBackward0>)\n","57000\n","tensor(6.7882, device='cuda:0', grad_fn=<NllLossBackward0>)\n","58000\n","tensor(6.7545, device='cuda:0', grad_fn=<NllLossBackward0>)\n","59000\n","tensor(6.7115, device='cuda:0', grad_fn=<NllLossBackward0>)\n","60000\n","tensor(6.7465, device='cuda:0', grad_fn=<NllLossBackward0>)\n","61000\n","tensor(6.8620, device='cuda:0', grad_fn=<NllLossBackward0>)\n","62000\n","tensor(7.1395, device='cuda:0', grad_fn=<NllLossBackward0>)\n","63000\n","tensor(6.7286, device='cuda:0', grad_fn=<NllLossBackward0>)\n","64000\n","tensor(6.6533, device='cuda:0', grad_fn=<NllLossBackward0>)\n","65000\n","tensor(6.7273, device='cuda:0', grad_fn=<NllLossBackward0>)\n","66000\n","tensor(6.6837, device='cuda:0', grad_fn=<NllLossBackward0>)\n","67000\n","tensor(6.7395, device='cuda:0', grad_fn=<NllLossBackward0>)\n","68000\n","tensor(6.6873, device='cuda:0', grad_fn=<NllLossBackward0>)\n","69000\n","tensor(6.7206, device='cuda:0', grad_fn=<NllLossBackward0>)\n","70000\n","tensor(6.7237, device='cuda:0', grad_fn=<NllLossBackward0>)\n","0.5\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","from transformers import AutoModel\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import balanced_accuracy_score\n","batch_size = 4\n","\n","alegzandra_finetuned_bert = AutoModel.from_pretrained(\"Alegzandra/romanian_bert-finetuned-on-REDv2-romanian\", output_hidden_states = True, num_labels=512).to(device)\n","\n","\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(train_data['class'])\n","\n","model = CNN(alegzandra_finetuned_bert).to(device)\n","\n","X_train, X_val, y_train, y_val = train_test_split(new_train_data, y, test_size=0.2, random_state=42)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","model.alegzandra_finetuned_bert.requires_grad_(False)\n","params = [param for param in model.parameters() if param.requires_grad]\n","optimizer = Adam(params, lr=0.0001)\n","\n","losses = []\n","for epoch in range(1):\n","    for i in range(0, len(new_train_data), batch_size):\n","        model.train()\n","        model.alegzandra_finetuned_bert.eval()\n","        if i % 1000 == 0:\n","            print(i)\n","            \n","        current_train_batch = new_train_data[i:i+batch_size]\n","        current_train_batch = [i.replace('ș', 's').replace('ț', 't').replace('Ș', 'S').replace('Ț', 'T') for i in current_train_batch]\n","        \n","        \n","        X_train = tokenizer(current_train_batch, padding=\"max_length\", truncation=True, return_tensors='pt', max_length=512)\n","        # print(X_train['input_ids'].shape)\n","        y_train = torch.tensor(y[i:i+batch_size], dtype=torch.int32).long().to(device)\n","        # print(X_train, y[i])\n","\n","        p_input_ids = X_train['input_ids'].to(device)\n","        p_attention_mask = X_train['attention_mask'].to(device)\n","\n","        # test = alegzandra_finetuned_bert(input_ids=p_input_ids, attention_mask=p_attention_mask).last_hidden_state\n","        # print(test.shape)\n","\n","        res = model(p_input_ids, p_attention_mask)\n","        # res = torch.argmax(res).to(device)\n","\n","        loss = loss_fn(res, y_train)\n","        if i % 1000 == 0:\n","            print(loss)\n","            torch.save(model.state_dict(), '/kaggle/working/model.pth')\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        # break\n","        \n","        if i + batch_size > len(new_train_data):\n","            torch.save(model.state_dict(), '/kaggle/working/model.pth')\n","#             break\n","\n","\n","        # print(res[0].shape)\n","        # Validation\n","    model.eval()\n","    model.alegzandra_finetuned_bert.eval()\n","    with torch.no_grad():\n","        for i in range(0, len(X_val), batch_size):\n","            X_val_test = tokenizer(X_val[i:i+batch_size], padding=\"max_length\", truncation=True, return_tensors='pt', max_length=512)\n","            y_val_test = torch.tensor(y_val[i:i+batch_size], dtype=torch.int32).long().to(device)\n","\n","            p_input_ids = X_val_test['input_ids'].to(device)\n","            p_attention_mask = X_val_test['attention_mask'].to(device)\n","\n","            res = model(p_input_ids, p_attention_mask)\n","            probabilities = torch.sigmoid(res)\n","            res = torch.argmax(probabilities, dim=-1).to(device)\n","            # if res < 0.5:\n","            #     res = 0\n","            # else:\n","            #     res = 1\n","\n","            # # Balanced accuracy\n","            balanced_accuracy = balanced_accuracy_score(y_val_test.cpu(), res.cpu())\n","            \n","            if i % 500 == 0:\n","                print(balanced_accuracy)\n","            break\n","            \n","#             if i + batch_size > len(X_val):\n","#                 break\n","            \n","torch.save(model.state_dict(), '/kaggle/working/model.pth')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T10:41:15.632571Z","iopub.status.busy":"2024-04-03T10:41:15.632100Z"},"trusted":true},"outputs":[],"source":["from pandas import DataFrame\n","\n","# Create data frame with id and class header\n","df = DataFrame(test_data['id'], columns=['id'])\n","\n","new_test_data = []\n","for i in range(len(test_data)):\n","    new_test_data.append((str(test_data['title'][i]) + \" \" + str(test_data[\"content\"][i])).replace(\"\\n\", \" \"))\n","\n","with torch.no_grad():\n","    model.eval()\n","    for i in range(0, len(test_data), batch_size):\n","        current_train_batch = new_test_data[i:i+batch_size]\n","        current_train_batch = [i.replace('ș', 's').replace('ț', 't').replace('Ș', 'S').replace('Ț', 'T') for i in current_train_batch]\n","        \n","        X_test = tokenizer(current_train_batch, padding=\"max_length\", truncation=True, return_tensors='pt', max_length=512)\n","        p_input_ids = X_test['input_ids'].to(device)\n","        p_attention_mask = X_test['attention_mask'].to(device)\n","\n","        res = model(p_input_ids, p_attention_mask)\n","        probabilities = torch.sigmoid(res)\n","        res = torch.argmax(probabilities, dim=-1).to(device)\n","        \n","        # Add all rows from res to df\n","        for j in range(len(res)):\n","            df.loc[i+j, 'class'] = int(res[j].item())\n","        \n","        \n","        \n","df.to_csv('/kaggle/working/submission.csv', index=False)\n","        \n","        "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4701222,"sourceId":7986540,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
